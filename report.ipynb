{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8YmERLjspGMH"
   },
   "source": [
    "## Table of Content\n",
    "\n",
    "[Purpose](#purpose)   \n",
    "[Data Understanding](#data_understanding)   \n",
    "[Data Preparation](#data_preparation)   \n",
    "[Modeling for Clustering](#clusteringmodel)  \n",
    "[Clustering results](#clustering)    \n",
    "[Modeling for Classification](#classificationmodel)  \n",
    "[Evaluation](#evaluation)  \n",
    "[References](#references)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "clDpC-2kpGMR"
   },
   "source": [
    "## Purpose <a class=\"anchor\" id=\"purpose\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "It7OxV2ypGMS"
   },
   "source": [
    "Describe the aim of this assigment here. What are the questions you are trying to solve?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Packages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Importing the necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Setting the objects spark and sc as stated in DataCamp\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JuZmF4SvpGMc"
   },
   "source": [
    "## Data Understanding<a class=\"anchor\" id=\"data_understanding\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path is:  data.csv\n",
      "['Area,Perimeter,MajorAxisLength,MinorAxisLength,AspectRation,Eccentricity,ConvexArea,EquivDiameter,Extent,Solidity,roundness,Compactness,ShapeFactor1,ShapeFactor2,ShapeFactor3,ShapeFactor4,Class', '28395,610.291,208.1781167,173.888747,1.197191424,0.549812187,28715,190.1410973,0.763922518,0.988855999,0.958027126,0.913357755,0.007331506,0.003147289,0.834222388,0.998723889,SEKER', '28734,638.018,200.5247957,182.7344194,1.097356461,0.411785251,29172,191.2727505,0.783968133,0.984985603,0.887033637,0.953860842,0.006978659,0.003563624,0.909850506,0.998430331,SEKER', '29380,624.11,212.8261299,175.9311426,1.209712656,0.562727317,29690,193.4109041,0.778113248,0.989558774,0.947849473,0.908774239,0.007243912,0.003047733,0.825870617,0.999066137,SEKER', '30008,645.884,210.557999,182.5165157,1.153638059,0.498615976,30724,195.4670618,0.782681273,0.976695743,0.903936374,0.928328835,0.007016729,0.003214562,0.861794425,0.994198849,SEKER']\n"
     ]
    }
   ],
   "source": [
    "#setting up rdd file and check if we created it correctly\n",
    "fileName = \"data.csv\"\n",
    "fileRDD = sc.textFile(fileName)\n",
    "print(\"File path is: \", fileName)\n",
    "print(fileRDD.take(5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+-----+\n",
      "| Area|Perimeter|MajorAxisLength|MinorAxisLength|AspectRation|Eccentricity|ConvexArea|EquivDiameter|     Extent|   Solidity|  roundness|Compactness|ShapeFactor1|ShapeFactor2|ShapeFactor3|ShapeFactor4|Class|\n",
      "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+-----+\n",
      "|28395|  610.291|    208.1781167|     173.888747| 1.197191424| 0.549812187|     28715|  190.1410973|0.763922518|0.988855999|0.958027126|0.913357755| 0.007331506| 0.003147289| 0.834222388| 0.998723889|SEKER|\n",
      "|28734|  638.018|    200.5247957|    182.7344194| 1.097356461| 0.411785251|     29172|  191.2727505|0.783968133|0.984985603|0.887033637|0.953860842| 0.006978659| 0.003563624| 0.909850506| 0.998430331|SEKER|\n",
      "|29380|   624.11|    212.8261299|    175.9311426| 1.209712656| 0.562727317|     29690|  193.4109041|0.778113248|0.989558774|0.947849473|0.908774239| 0.007243912| 0.003047733| 0.825870617| 0.999066137|SEKER|\n",
      "|30008|  645.884|     210.557999|    182.5165157| 1.153638059| 0.498615976|     30724|  195.4670618|0.782681273|0.976695743|0.903936374|0.928328835| 0.007016729| 0.003214562| 0.861794425| 0.994198849|SEKER|\n",
      "|30140|  620.134|    201.8478822|    190.2792788|  1.06079802| 0.333679658|     30417|   195.896503|0.773098035| 0.99089325|0.984877069|0.970515523|  0.00669701| 0.003664972| 0.941900381| 0.999166059|SEKER|\n",
      "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#creating data frame from given csv file and check it\n",
    "OD = spark.read.csv(fileName, header=True, inferSchema=True)\n",
    "OD.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Count (Task 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "['Area',\n 'Perimeter',\n 'MajorAxisLength',\n 'MinorAxisLength',\n 'AspectRation',\n 'Eccentricity',\n 'ConvexArea',\n 'EquivDiameter',\n 'Extent',\n 'Solidity',\n 'roundness',\n 'Compactness',\n 'ShapeFactor1',\n 'ShapeFactor2',\n 'ShapeFactor3',\n 'ShapeFactor4',\n 'Class',\n '28395',\n '610.291',\n '208.1781167']"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in order not to spoil data frame we have, created a new data frame and split by \",\" to create an array includes eah element in the rdd\n",
    "#and take a look at to the top\n",
    "wordCountRDD = fileRDD.flatMap(lambda f: f.split(\",\"))\n",
    "wordCountRDD.take(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "[('Area', 1),\n ('Perimeter', 1),\n ('MajorAxisLength', 1),\n ('MinorAxisLength', 1),\n ('AspectRation', 1),\n ('Eccentricity', 1),\n ('ConvexArea', 1),\n ('EquivDiameter', 1),\n ('Extent', 1),\n ('Solidity', 1),\n ('roundness', 1),\n ('Compactness', 1),\n ('ShapeFactor1', 1),\n ('ShapeFactor2', 1),\n ('ShapeFactor3', 1),\n ('ShapeFactor4', 1),\n ('Class', 1),\n ('28395', 1),\n ('610.291', 1),\n ('208.1781167', 1)]"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rdd is done as key value pairs and take a look at\n",
    "wordCountRDD = wordCountRDD.map(lambda f: (f,1))\n",
    "wordCountRDD.take(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "[('DERMASON', 3546),\n ('SIRA', 2636),\n ('SEKER', 2027),\n ('HOROZ', 1928),\n ('CALI', 1630),\n ('BARBUNYA', 1322),\n ('BOMBAY', 522)]"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sum up the values that have the same values and sort them by using the values and take a look at\n",
    "wordCountRDD = wordCountRDD.reduceByKey(lambda f,h: f+h)\n",
    "wordCountRDD = wordCountRDD.sortBy(lambda f: f[1], ascending=False)\n",
    "wordCountRDD.take(7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Provide analysis and statistical information about the data set. How much data is there? What are the data types? What are the largest, smallest and average values of these data?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileRDD type is:  <class 'pyspark.rdd.RDD'>\n",
      "Total number of lines is:  13612\n"
     ]
    }
   ],
   "source": [
    "#Checking if the rdd file is created correctly and total line count\n",
    "print(\"fileRDD type is: \", type(fileRDD))\n",
    "print(\"Total number of lines is: \", fileRDD.count())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of rows: 13611\n"
     ]
    }
   ],
   "source": [
    "#total number of rows\n",
    "print(\"total number of rows:\", OD.count())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Area: integer (nullable = true)\n",
      " |-- Perimeter: double (nullable = true)\n",
      " |-- MajorAxisLength: double (nullable = true)\n",
      " |-- MinorAxisLength: double (nullable = true)\n",
      " |-- AspectRation: double (nullable = true)\n",
      " |-- Eccentricity: double (nullable = true)\n",
      " |-- ConvexArea: integer (nullable = true)\n",
      " |-- EquivDiameter: double (nullable = true)\n",
      " |-- Extent: double (nullable = true)\n",
      " |-- Solidity: double (nullable = true)\n",
      " |-- roundness: double (nullable = true)\n",
      " |-- Compactness: double (nullable = true)\n",
      " |-- ShapeFactor1: double (nullable = true)\n",
      " |-- ShapeFactor2: double (nullable = true)\n",
      " |-- ShapeFactor3: double (nullable = true)\n",
      " |-- ShapeFactor4: double (nullable = true)\n",
      " |-- Class: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking the column values' types\n",
    "OD.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average values of each column is: \n",
      "+-----------------+------------------+------------------+--------------------+------------------+------------------+-----------------+--------------------+-----------------+------------------+-----------------+------------------+------------------+------------------+--------------------+--------------------+\n",
      "|   avg(roundness)|         avg(Area)|avg(EquivDiameter)|avg(MinorAxisLength)|  avg(Compactness)| avg(ShapeFactor3)|  avg(ConvexArea)|   avg(ShapeFactor2)|avg(Eccentricity)| avg(AspectRation)|   avg(Perimeter)|       avg(Extent)| avg(ShapeFactor4)|     avg(Solidity)|avg(MajorAxisLength)|   avg(ShapeFactor1)|\n",
      "+-----------------+------------------+------------------+--------------------+------------------+------------------+-----------------+--------------------+-----------------+------------------+-----------------+------------------+------------------+------------------+--------------------+--------------------+\n",
      "|0.873281831305413|53048.284549261625|253.06421992490445|   202.2707140828817|0.7998636818695875|0.6435901812970417|53768.20020571596|0.001715947338917041|0.750894929372346|1.5832419790188144|855.2834585996654|0.7497327873564055|0.9950633118301326|0.9871428435655719|   320.1418673032194|0.006563608507383666|\n",
      "+-----------------+------------------+------------------+--------------------+------------------+------------------+-----------------+--------------------+-----------------+------------------+-----------------+------------------+------------------+------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Average values of each column is: \")\n",
    "OD.agg({\n",
    "    'Area': 'avg',\n",
    "    'Perimeter': 'avg',\n",
    "    'MajorAxisLength': 'avg',\n",
    "    'MinorAxisLength': 'avg',\n",
    "    'AspectRation': 'avg',\n",
    "    'Eccentricity': 'avg',\n",
    "    'ConvexArea': 'avg',\n",
    "    'EquivDiameter': 'avg',\n",
    "    'Extent': 'avg',\n",
    "    'Solidity': 'avg',\n",
    "    'roundness': 'avg',\n",
    "    'Compactness':'avg',\n",
    "    'ShapeFactor1':'avg',\n",
    "    'ShapeFactor2':'avg',\n",
    "    'ShapeFactor3':'avg',\n",
    "    'ShapeFactor4':'avg'\n",
    "}).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min values of each column is: \n",
      "+--------------+---------+------------------+--------------------+----------------+-----------------+---------------+-----------------+-----------------+-----------------+--------------+-----------+-----------------+-------------+--------------------+-----------------+\n",
      "|min(roundness)|min(Area)|min(EquivDiameter)|min(MinorAxisLength)|min(Compactness)|min(ShapeFactor3)|min(ConvexArea)|min(ShapeFactor2)|min(Eccentricity)|min(AspectRation)|min(Perimeter)|min(Extent)|min(ShapeFactor4)|min(Solidity)|min(MajorAxisLength)|min(ShapeFactor1)|\n",
      "+--------------+---------+------------------+--------------------+----------------+-----------------+---------------+-----------------+-----------------+-----------------+--------------+-----------+-----------------+-------------+--------------------+-----------------+\n",
      "|   0.489618256|    20420|       161.2437642|         122.5126535|     0.640576759|      0.410338584|          20684|       5.64169E-4|      0.218951263|      1.024867596|       524.736|0.555314717|      0.947687403|  0.919246157|          183.601165|      0.002778013|\n",
      "+--------------+---------+------------------+--------------------+----------------+-----------------+---------------+-----------------+-----------------+-----------------+--------------+-----------+-----------------+-------------+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Min values of each column is: \")\n",
    "OD.agg({\n",
    "    'Area': 'min',\n",
    "    'Perimeter': 'min',\n",
    "    'MajorAxisLength': 'min',\n",
    "    'MinorAxisLength': 'min',\n",
    "    'AspectRation': 'min',\n",
    "    'Eccentricity': 'min',\n",
    "    'ConvexArea': 'min',\n",
    "    'EquivDiameter': 'min',\n",
    "    'Extent': 'min',\n",
    "    'Solidity': 'min',\n",
    "    'roundness': 'min',\n",
    "    'Compactness':'min',\n",
    "    'ShapeFactor1':'min',\n",
    "    'ShapeFactor2':'min',\n",
    "    'ShapeFactor3':'min',\n",
    "    'ShapeFactor4':'min'\n",
    "}).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max values of each column is: \n",
      "+--------------+---------+------------------+--------------------+----------------+-----------------+---------------+-----------------+-----------------+-----------------+--------------+-----------+-----------------+-------------+--------------------+-----------------+\n",
      "|max(roundness)|max(Area)|max(EquivDiameter)|max(MinorAxisLength)|max(Compactness)|max(ShapeFactor3)|max(ConvexArea)|max(ShapeFactor2)|max(Eccentricity)|max(AspectRation)|max(Perimeter)|max(Extent)|max(ShapeFactor4)|max(Solidity)|max(MajorAxisLength)|max(ShapeFactor1)|\n",
      "+--------------+---------+------------------+--------------------+----------------+-----------------+---------------+-----------------+-----------------+-----------------+--------------+-----------+-----------------+-------------+--------------------+-----------------+\n",
      "|     0.9906854|   254616|       569.3743583|         460.1984968|     0.987302969|      0.974767153|         263261|      0.003664972|      0.911422968|      2.430306447|       1985.37|0.866194641|       0.99973253|    0.9946775|         738.8601535|      0.010451169|\n",
      "+--------------+---------+------------------+--------------------+----------------+-----------------+---------------+-----------------+-----------------+-----------------+--------------+-----------+-----------------+-------------+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Max values of each column is: \")\n",
    "OD.agg({\n",
    "    'Area': 'max',\n",
    "    'Perimeter': 'max',\n",
    "    'MajorAxisLength': 'max',\n",
    "    'MinorAxisLength': 'max',\n",
    "    'AspectRation': 'max',\n",
    "    'Eccentricity': 'max',\n",
    "    'ConvexArea': 'max',\n",
    "    'EquivDiameter': 'max',\n",
    "    'Extent': 'max',\n",
    "    'Solidity': 'max',\n",
    "    'roundness': 'max',\n",
    "    'Compactness':'max',\n",
    "    'ShapeFactor1':'max',\n",
    "    'ShapeFactor2':'max',\n",
    "    'ShapeFactor3':'max',\n",
    "    'ShapeFactor4':'max'\n",
    "}).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#percentages of the ClassIndexes\n",
    "print(\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation<a class=\"anchor\" id=\"data_preparation\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+----------+\n",
      "| Area|Perimeter|MajorAxisLength|MinorAxisLength|AspectRation|Eccentricity|ConvexArea|EquivDiameter|     Extent|   Solidity|  roundness|Compactness|ShapeFactor1|ShapeFactor2|ShapeFactor3|ShapeFactor4|ClassIndex|\n",
      "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+----------+\n",
      "|28395|  610.291|    208.1781167|     173.888747| 1.197191424| 0.549812187|     28715|  190.1410973|0.763922518|0.988855999|0.958027126|0.913357755| 0.007331506| 0.003147289| 0.834222388| 0.998723889|       2.0|\n",
      "|28734|  638.018|    200.5247957|    182.7344194| 1.097356461| 0.411785251|     29172|  191.2727505|0.783968133|0.984985603|0.887033637|0.953860842| 0.006978659| 0.003563624| 0.909850506| 0.998430331|       2.0|\n",
      "|29380|   624.11|    212.8261299|    175.9311426| 1.209712656| 0.562727317|     29690|  193.4109041|0.778113248|0.989558774|0.947849473|0.908774239| 0.007243912| 0.003047733| 0.825870617| 0.999066137|       2.0|\n",
      "|30008|  645.884|     210.557999|    182.5165157| 1.153638059| 0.498615976|     30724|  195.4670618|0.782681273|0.976695743|0.903936374|0.928328835| 0.007016729| 0.003214562| 0.861794425| 0.994198849|       2.0|\n",
      "|30140|  620.134|    201.8478822|    190.2792788|  1.06079802| 0.333679658|     30417|   195.896503|0.773098035| 0.99089325|0.984877069|0.970515523|  0.00669701| 0.003664972| 0.941900381| 0.999166059|       2.0|\n",
      "|30279|  634.927|    212.5605564|    181.5101816| 1.171066849|  0.52040066|     30600|  196.3477022|0.775688485|0.989509804|0.943851783|0.923725952| 0.007020065| 0.003152779| 0.853269634| 0.999235781|       2.0|\n",
      "|30477|  670.033|    211.0501553|    184.0390501| 1.146768336| 0.489477894|     30970|  196.9886332|0.762401501|0.984081369|0.853079869|0.933373552| 0.006924899| 0.003242016| 0.871186188| 0.999048736|       2.0|\n",
      "|30519|  629.727|    212.9967551|    182.7372038| 1.165590535| 0.513759558|     30847|  197.1243203|0.770681818|0.989366875|0.967109244|0.925480392| 0.006979152| 0.003158285| 0.856513956|  0.99834456|       2.0|\n",
      "|30685|  635.681|    213.5341452|    183.1571463| 1.165852108|  0.51408086|     31044|   197.659696|0.771561479|0.988435769|0.954239808|0.925658498|  0.00695891|  0.00315155| 0.856843654| 0.998952981|       2.0|\n",
      "|30834|  631.934|    217.2278128|    180.8974686|   1.2008339| 0.553642225|     31120|  198.1390121|0.783682806|0.990809769| 0.97027823| 0.91212543| 0.007045074|  0.00300804|   0.8319728| 0.999061142|       2.0|\n",
      "|30917|  640.765|    213.5600894|    184.4398709| 1.157884618| 0.504102365|     31280|  198.4055115|0.770805285|0.988395141| 0.94625818|0.929038343| 0.006907529|  0.00317422| 0.863112242| 0.999384389|       2.0|\n",
      "|31091|  638.558|    210.4862549|    188.3268476| 1.117664622| 0.446621924|     31458|  198.9630385|0.786377317|0.988333651|0.958172836|0.945254305| 0.006770006| 0.003333984|   0.8935057| 0.998639711|       2.0|\n",
      "|31107|  640.594|    214.6485485|    184.9692526| 1.160455295| 0.507365875|     31423|  199.0142269|0.761046142|0.989943672|0.952581757|0.927163162| 0.006900329| 0.003145388| 0.859631529| 0.997563959|       2.0|\n",
      "|31158|  642.626|    216.4848362|    183.6443122| 1.178826797| 0.529514251|     31492|  199.1773023|0.798759229|0.989394132|0.948119004| 0.92005198|  0.00694797| 0.003071052| 0.846495646| 0.997871751|       2.0|\n",
      "|31158|  641.105|    212.0669751|    187.1929601| 1.132879009| 0.469924157|     31474|  199.1773023|0.781313473|0.989959967|0.952623101|0.939218858| 0.006806181|  0.00326701| 0.882132064| 0.999348898|       2.0|\n",
      "|31178|  636.888|    212.9759252|    186.5620882| 1.141582018| 0.482352224|     31520|  199.2412169|0.764110482|0.989149746|0.965899596|0.935510513| 0.006830968| 0.003227429| 0.875179919| 0.999089658|       2.0|\n",
      "|31202|  644.454|    215.6406947|    184.4716842| 1.168963657| 0.517871223|     31573|  199.3178875|0.779192888|0.988249454|0.944079243|0.924305534| 0.006911118| 0.003111647|  0.85434072| 0.998693253|       2.0|\n",
      "|31203|  639.782|     215.067737|    184.8748759| 1.163315112| 0.510946829|     31558|  199.3210815|0.762984155|0.988750871|0.957948542|0.926782809| 0.006892534| 0.003136682| 0.858926376| 0.999202033|       2.0|\n",
      "|31272|  638.666|    212.4503189|     187.535939| 1.132851229| 0.469883494|     31593|  199.5413417|0.770322199|0.989839521|0.963425036|0.939237666| 0.006793627| 0.003261246| 0.882167393| 0.999364415|       2.0|\n",
      "|31335|  635.011|    216.7900923|    184.1634403| 1.177161395|  0.52758671|     31599|  199.7422367|0.774277242|0.991645305|0.976510834|0.921362386| 0.006918465| 0.003075469| 0.848908647| 0.999302487|       2.0|\n",
      "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\"Class\" column has categorical string values and this makes our model cannot be trained\n",
    "#we are using StringIndexer to handle this situation\n",
    "#and also drop the \"Class\" column\n",
    "#StringIndexer indexes categorical variables by their frequency so in this case:\n",
    "#0: DERMASON, 1: SIRA, 2: SEKER, 3: HOROZ, 4: CALI, 5: BARBUNYA, 6: BOMBAY\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer = StringIndexer(inputCol=\"Class\", outputCol=\"ClassIndex\")\n",
    "OD = indexer.fit(OD).transform(OD)\n",
    "OD = OD.drop(\"Class\")\n",
    "OD.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Explain what kind of data transformations, feature selection and/or engineering you will perform."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Area: integer (nullable = true)\n",
      " |-- Perimeter: double (nullable = true)\n",
      " |-- MajorAxisLength: double (nullable = true)\n",
      " |-- MinorAxisLength: double (nullable = true)\n",
      " |-- AspectRation: double (nullable = true)\n",
      " |-- Eccentricity: double (nullable = true)\n",
      " |-- ConvexArea: integer (nullable = true)\n",
      " |-- EquivDiameter: double (nullable = true)\n",
      " |-- Extent: double (nullable = true)\n",
      " |-- Solidity: double (nullable = true)\n",
      " |-- roundness: double (nullable = true)\n",
      " |-- Compactness: double (nullable = true)\n",
      " |-- ShapeFactor1: double (nullable = true)\n",
      " |-- ShapeFactor2: double (nullable = true)\n",
      " |-- ShapeFactor3: double (nullable = true)\n",
      " |-- ShapeFactor4: double (nullable = true)\n",
      " |-- ClassIndex: double (nullable = false)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "13611"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#as we can see above, some values are null so we should drop that rows all\n",
    "#we googled that why are nullables true still but we found that PySpark dataframes has a bug for nullables bool values\n",
    "#we can check the number of total rows and compare it to the default number of rows and we can see that data has no null values\n",
    "OD = OD.na.drop(how='any')\n",
    "OD.printSchema()\n",
    "\n",
    "OD.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Area: double (nullable = true)\n",
      " |-- Perimeter: double (nullable = true)\n",
      " |-- MajorAxisLength: double (nullable = true)\n",
      " |-- MinorAxisLength: double (nullable = true)\n",
      " |-- AspectRation: double (nullable = true)\n",
      " |-- Eccentricity: double (nullable = true)\n",
      " |-- ConvexArea: double (nullable = true)\n",
      " |-- EquivDiameter: double (nullable = true)\n",
      " |-- Extent: double (nullable = true)\n",
      " |-- Solidity: double (nullable = true)\n",
      " |-- roundness: double (nullable = true)\n",
      " |-- Compactness: double (nullable = true)\n",
      " |-- ShapeFactor1: double (nullable = true)\n",
      " |-- ShapeFactor2: double (nullable = true)\n",
      " |-- ShapeFactor3: double (nullable = true)\n",
      " |-- ShapeFactor4: double (nullable = true)\n",
      " |-- ClassIndex: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "#all of the columns have double values except by \"Area\" and \"ConvexArea\" so we should convert them into double too\n",
    "\n",
    "OD = OD.withColumn(\"Area\", OD[\"Area\"].cast(DoubleType()))\n",
    "OD = OD.withColumn(\"ConvexArea\", OD[\"ConvexArea\"].cast(DoubleType()))\n",
    "OD.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Eccentricity: double (nullable = true)\n",
      " |-- Extent: double (nullable = true)\n",
      " |-- Solidity: double (nullable = true)\n",
      " |-- roundness: double (nullable = true)\n",
      " |-- Compactness: double (nullable = true)\n",
      " |-- ShapeFactor1: double (nullable = true)\n",
      " |-- ShapeFactor2: double (nullable = true)\n",
      " |-- ShapeFactor3: double (nullable = true)\n",
      " |-- ShapeFactor4: double (nullable = true)\n",
      " |-- ClassIndex: double (nullable = true)\n",
      " |-- Area_Scaled: double (nullable = true)\n",
      " |-- EquivDiameter_Scaled: double (nullable = true)\n",
      " |-- MinorAxisLength_Scaled: double (nullable = true)\n",
      " |-- ConvexArea_Scaled: double (nullable = true)\n",
      " |-- AspectRation_Scaled: double (nullable = true)\n",
      " |-- Perimeter_Scaled: double (nullable = true)\n",
      " |-- MajorAxisLength_Scaled: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.linalg import VectorUDT\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "ND = OD.select(\"*\")\n",
    "\n",
    "#creating normalized dataset(ND)\n",
    "columns_to_normalize = [\"Area\", \"EquivDiameter\", \"MinorAxisLength\", \"ConvexArea\", \"AspectRation\", \"Perimeter\", \"MajorAxisLength\"]\n",
    "assembler = [VectorAssembler(inputCols=[col], outputCol=col+\"_Vect\") for col in columns_to_normalize]\n",
    "scaler = [MinMaxScaler(inputCol=col+\"_Vect\", outputCol=col+\"_Scaled\") for col in columns_to_normalize]\n",
    "pipeline = Pipeline(stages=assembler + scaler)\n",
    "\n",
    "NDModel = pipeline.fit(ND)\n",
    "ND = NDModel.transform(ND)\n",
    "\n",
    "for col in columns_to_normalize:\n",
    "    ND = ND.drop(col+\"_Vect\")\n",
    "    ND = ND.drop(col)\n",
    "\n",
    "\n",
    "firstElem = F.udf(lambda v: float(v[0]), FloatType())\n",
    "NDX = ND.select([firstElem(col+\"_Scaled\").alias(col+\"_Scaled\") for col in columns_to_normalize])\n",
    "for col in columns_to_normalize:\n",
    "#     print(col)\n",
    "#     if col not in ND.schema.names:\n",
    "#         firstElem(col+\"_Scaled\").alias(col+\"_Scaled\")\n",
    "    NDX = NDX.withColumn(col+\"_Scaled\", F.col(col+\"_Scaled\").cast(DoubleType()))\n",
    "\n",
    "for col in columns_to_normalize:\n",
    "    ND = ND.drop(col+\"_Scaled\")\n",
    "\n",
    "def append_ODs(OD1,OD2):\n",
    "    list1 = OD1.columns\n",
    "    list2 = OD2.columns\n",
    "    for col in list2:\n",
    "        if(col not in list1):\n",
    "            OD1 = OD1.withColumn(col, F.lit(None))\n",
    "    for col in list1:\n",
    "        if(col not in list2):\n",
    "            OD2 = OD2.withColumn(col, F.lit(None))\n",
    "    return OD1.unionByName(OD2)\n",
    "\n",
    "ND = append_ODs(ND,NDX)\n",
    "\n",
    "ND.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L5yg37-IpGM1"
   },
   "source": [
    "## Modeling for Clustering <a class=\"anchor\" id=\"clusteringmodel\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "85XeuwetpGM2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vXXqce-LpGM4"
   },
   "source": [
    "Which model will be used? Why? What parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KdjxO3EF9QWy"
   },
   "source": [
    "## Clustering results<a class=\"anchor\" id=\"clustering\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9yoeXEZG9X3Q"
   },
   "source": [
    "Present the clustering results and graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AhZqLaTy9lC0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86MgAti_9ljX"
   },
   "source": [
    "Evaluate your Clustering model. Provide results, tables, charts, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ebDW7Pl9xkV"
   },
   "source": [
    "\n",
    "## Modeling for Classification <a class=\"anchor\" id=\"classificationmodel\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f0t3y0Gh-iY8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "osXXZDxS-hVD"
   },
   "source": [
    "Which model will be used? Why? What parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Vxg2ptipGNZ"
   },
   "source": [
    "## Evaluation<a class=\"anchor\" id=\"evaluation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jpLkiP1xpGNa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OA-dJVmFpGNy"
   },
   "source": [
    "Evaluate your model. Provide results, tables, charts, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qREn94uEpGNy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e-4dIZj6pGN4"
   },
   "source": [
    "## References<a class=\"anchor\" id=\"references\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2LhJNQYopGN5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i9WaoKuZpGN_"
   },
   "source": [
    "List all the sources you used during your work.\n",
    "This includes jupyter notebooks you found on Internet.\n",
    "Remeber, your work may not be an original one. However, this document must be genuine. Copy and paste kind of deliveries will be punished badly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g9j2kMIPpGOA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qe-ObfH2pGOH"
   },
   "source": [
    "\n",
    "**Disclaimer!** <font color='grey'>This notebook was prepared by <student name(s)> as an assigment for the *BBM469 - Data Intensive Applications Laboratory* class. The notebook is available for educational purposes only. There is no guarantee on the correctness of the content provided as it is a student work.\n",
    "\n",
    "If you think there is any copyright violation, please let us [know](https://forms.gle/BNNRB2kR8ZHVEREq8). \n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "bbm469_hw3_template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}